{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High Frequency Trading Algorithm\n",
    "\n",
    "You have been tasked by the investment firm Renaissance High Frequency Trading (RHFT) to develop an automated trading strategy utilizing a combination of machine learning algorithms and high frequency algorithms. RHFT wants this new algorithm to be based on stock market data of the 30 stocks in the Dow Jones at the minute level and to conduct buys and sells every minute based on 1 min, 5 min, and 10 min Momentum. The CIO asked you to choose the Machine Learning Algorithm best suited for this task and wants you to execute the trades via Alpaca's API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Set-Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import alpaca_trade_api as tradeapi\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "# from dotenv import load_dotenv\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load .env enviroment variables\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Alpaca API key and secret\n",
    "\n",
    "api_key = 'PKKHA6KCMXSEQPSP9ZI9'\n",
    "secret_key = '4yLfOkgUrO898gbNKPcXEH0Gx0taRLDLv9TdvAUJ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Alpaca API object, specifying use of the paper trading account:\n",
    "\n",
    "base_url = \"https://paper-api.alpaca.markets\"\n",
    "alpaca = tradeapi.REST(api_key, secret_key, base_url, api_version='v2')\n",
    "account = alpaca.get_account()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Train and Compare Multiple Machine Learning Algorithms\n",
    "\n",
    " In this section, you'll train each of the requested algorithms and compare performance. Be sure to use the same parameters and training steps for each model. This is necessary to compare each model accurately.\n",
    "\n",
    "### Preprocessing Data\n",
    "\n",
    "#### 1. Generate your feature data (`X`) and target data (`y`):\n",
    "* Create a dataframe `X` that contains all the columns from the returns dataframe that will be used to predict `F_1_m_returns`.\n",
    "* Create a variable, called `y`, that is equal 1 if `F_1_m_returns` is larger than 0. This will be our target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>F_1_m_returns</th>\n",
       "      <th>1_m_returns</th>\n",
       "      <th>5_m_returns</th>\n",
       "      <th>10_m_returns</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>level_0</th>\n",
       "      <th>level_1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">FB</th>\n",
       "      <th>2021-01-05 09:40:00-05:00</th>\n",
       "      <td>0.000814</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.001260</td>\n",
       "      <td>0.004758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-05 09:41:00-05:00</th>\n",
       "      <td>0.000887</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>0.001889</td>\n",
       "      <td>0.004941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-05 09:42:00-05:00</th>\n",
       "      <td>0.000628</td>\n",
       "      <td>0.000887</td>\n",
       "      <td>0.001999</td>\n",
       "      <td>0.003782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-05 09:43:00-05:00</th>\n",
       "      <td>0.000480</td>\n",
       "      <td>0.000628</td>\n",
       "      <td>0.003408</td>\n",
       "      <td>0.007850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-05 09:44:00-05:00</th>\n",
       "      <td>-0.001291</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>0.002886</td>\n",
       "      <td>0.005416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   F_1_m_returns  1_m_returns  5_m_returns  \\\n",
       "level_0 level_1                                                              \n",
       "FB      2021-01-05 09:40:00-05:00       0.000814     0.000074     0.001260   \n",
       "        2021-01-05 09:41:00-05:00       0.000887     0.000814     0.001889   \n",
       "        2021-01-05 09:42:00-05:00       0.000628     0.000887     0.001999   \n",
       "        2021-01-05 09:43:00-05:00       0.000480     0.000628     0.003408   \n",
       "        2021-01-05 09:44:00-05:00      -0.001291     0.000480     0.002886   \n",
       "\n",
       "                                   10_m_returns  \n",
       "level_0 level_1                                  \n",
       "FB      2021-01-05 09:40:00-05:00      0.004758  \n",
       "        2021-01-05 09:41:00-05:00      0.004941  \n",
       "        2021-01-05 09:42:00-05:00      0.003782  \n",
       "        2021-01-05 09:43:00-05:00      0.007850  \n",
       "        2021-01-05 09:44:00-05:00      0.005416  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset returns.csv and set the index to level_0 and time\n",
    "\n",
    "returns = pd.read_csv('returns.csv', index_col = ['level_0', 'level_1'])\n",
    "returns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a separate dataframe for features and define the target variable as a binary target\n",
    "X = returns.drop('F_1_m_returns', axis=1)\n",
    "\n",
    "# Create the target variable\n",
    "Y = returns['F_1_m_returns']\n",
    "Y = np.where(Y>0, 1, 0)\n",
    "Y = pd.Series(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note:\n",
    "> Notice that we don't use shuffle when splitting the dataset into a training and testing dataset. \n",
    "\n",
    "> We want to keep the original ordering of the data, so we don't end up using observations in the future to predict past observations,\n",
    "\n",
    "> This is a critical mistake known as look ahead bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Use the train_test_split library to split the dataset into a training and testing dataset, with 70% used for testing\n",
    "* Set the shuffle parameter to False, so that you use the first 70% for training to prvent look ahead bias.\n",
    "* Make sure you have these 4 variables: `X_train`, `X_test`, `y_train`, `y_test`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train_test_split \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset without shuffling\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, train_size=0.7, random_state=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Use the `Counter` function to test the distribution of the data. \n",
    "* The result of `Counter({1: 668, 0: 1194})` reveals the data is indeed unbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 668, 0: 1193})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the Counter function from the collections library\n",
    "from collections import Counter\n",
    "\n",
    "# Use Counter to count the number 1s and 0 in y_train\n",
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Balance the dataset with the Oversampler libary, setting `random state= 1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import RandomOverSampler from the imblearn library\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Use RandomOverSampler to resample the datase using random_state=1\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Test the distribution once again with `Counter`. The new result of `Counter({1: 1194, 0: 1194})` shows the data is now balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 1193, 0: 1193})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use Counter again to verify imbalance removed\n",
    "\n",
    "Counter(y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "\n",
    "#### 1. The first cells in this section provide an example of how to fit and train your model using the `LogisticRegression` model from sklearn:\n",
    "* Import select model.\n",
    "* Instantiate model object.\n",
    "* Fit the model to the resampled data - `X_resampled` and `y_resampled`.\n",
    "* Predict the model using `X_test`.\n",
    "* Print the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import classification_report from sklearn\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5396    0.5197    0.5295       406\n",
      "           1     0.5221    0.5420    0.5318       393\n",
      "\n",
      "    accuracy                         0.5307       799\n",
      "   macro avg     0.5309    0.5308    0.5307       799\n",
      "weighted avg     0.5310    0.5307    0.5306       799\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import LogisticRegression from sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create a LogisticRegression model and train it on the X_resampled data we created before\n",
    "log_model = LogisticRegression()\n",
    "log_model.fit(X_resampled, y_resampled)  \n",
    "\n",
    "# Use the model you trained to predict using X_test\n",
    "y_pred = log_model.predict(X_test)   \n",
    "\n",
    "# Print out a classification report toevaluate performance\n",
    "print(classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Use the same approach as above to train and test the following ML Algorithms:\n",
    "* [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
    "* [GradientBoostingClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html)\n",
    "* [AdaBoostClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html)\n",
    "* [XGBClassifier](https://xgboost.readthedocs.io/en/latest/python/python_api.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5051    0.6133    0.5539       406\n",
      "           1     0.4869    0.3791    0.4263       393\n",
      "\n",
      "    accuracy                         0.4981       799\n",
      "   macro avg     0.4960    0.4962    0.4901       799\n",
      "weighted avg     0.4961    0.4981    0.4912       799\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import RandomForestClassifier from sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create a RandomForestClassifier model and train it on the X_resampled data we created before\n",
    "rfc_model = RandomForestClassifier()\n",
    "rfc_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Use the model you trained to predict using X_test\n",
    "y_pred = rfc_model.predict(X_test)\n",
    "\n",
    "# Print out a classification report to evaluate performance\n",
    "print(classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5180    0.5320    0.5249       406\n",
      "           1     0.5026    0.4885    0.4955       393\n",
      "\n",
      "    accuracy                         0.5106       799\n",
      "   macro avg     0.5103    0.5103    0.5102       799\n",
      "weighted avg     0.5104    0.5106    0.5104       799\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import RandomForestClassifier from sklearn\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Create a GradientBoostingClassifier model and train it on the X_resampled data we created before\n",
    "gbc_model = GradientBoostingClassifier()\n",
    "gbc_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Use the model you trained to predict using X_test\n",
    "y_pred = gbc_model.predict(X_test)\n",
    "\n",
    "# Print out a classification report to evaluate performance\n",
    "print(classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5180    0.5320    0.5249       406\n",
      "           1     0.5026    0.4885    0.4955       393\n",
      "\n",
      "    accuracy                         0.5106       799\n",
      "   macro avg     0.5103    0.5103    0.5102       799\n",
      "weighted avg     0.5104    0.5106    0.5104       799\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import RandomForestClassifier from sklearn\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Create a AdaBoostClassifier model and train it on the X_resampled data we created before\n",
    "abc_model = AdaBoostClassifier()\n",
    "abc_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Use the model you trained to predict using X_test\n",
    "y_pred = gbc_model.predict(X_test)\n",
    "\n",
    "# Print out a classification report to evaluate performance\n",
    "print(classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:40:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4906    0.5788    0.5311       406\n",
      "           1     0.4656    0.3791    0.4180       393\n",
      "\n",
      "    accuracy                         0.4806       799\n",
      "   macro avg     0.4781    0.4790    0.4745       799\n",
      "weighted avg     0.4783    0.4806    0.4754       799\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import RandomForestClassifier from sklearn\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Create a XGBClassifier model and train it on the X_resampled data we created before\n",
    "xgbc_model = XGBClassifier()\n",
    "xgbc_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Use the model you trained to predict using X_test\n",
    "y_pred = xgbc_model.predict(X_test)\n",
    "\n",
    "# Print out a classification report to evaluate performance\n",
    "print(classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the performance of each model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Using the classification report for each model, choose the model with the highest precision for use in your algo-trading program.\n",
    "#### 2. Save the selected model with the `joblib` libary to avoid retraining every time you wish to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['log_model.pkl']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the joblib library \n",
    "import joblib\n",
    "\n",
    "# Use the library to save the model that you want to use for trading\n",
    "joblib.dump(log_model, 'log_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Implement the strongest model using Apaca API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Develop the Algorithm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Use the provided code to ping the Alpaca API and create the DataFrame needed to feed data into the model.\n",
    "   * This code will also store the correct feature data in `X` for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                FB      AMZN     AAPL    NFLX    GOOGL  \\\n",
      "time                                                                     \n",
      "2021-01-06 14:50:00-05:00  264.610  3146.960  127.110  506.54  1721.82   \n",
      "2021-01-06 14:51:00-05:00  264.630  3146.910  127.430  506.54  1721.82   \n",
      "2021-01-06 14:52:00-05:00  264.830  3147.980  127.720  506.69  1723.67   \n",
      "2021-01-06 14:53:00-05:00  264.525  3148.570  127.510  506.01  1723.67   \n",
      "2021-01-06 14:54:00-05:00  264.560  3147.840  127.645  506.01  1720.84   \n",
      "2021-01-06 14:55:00-05:00  264.880  3150.330  127.920  506.30  1720.60   \n",
      "2021-01-06 14:56:00-05:00  264.965  3150.610  128.150  506.72  1721.10   \n",
      "2021-01-06 14:57:00-05:00  264.980  3151.745  127.980  507.07  1720.07   \n",
      "2021-01-06 14:58:00-05:00  265.000  3149.280  127.850  506.33  1720.07   \n",
      "2021-01-06 14:59:00-05:00  265.360  3150.840  127.930  506.13  1720.48   \n",
      "2021-01-06 15:00:00-05:00  264.840  3148.580  127.630  506.43  1720.48   \n",
      "\n",
      "                              MSFT    TSLA  \n",
      "time                                        \n",
      "2021-01-06 14:50:00-05:00  213.930  753.33  \n",
      "2021-01-06 14:51:00-05:00  214.080  757.44  \n",
      "2021-01-06 14:52:00-05:00  214.220  759.03  \n",
      "2021-01-06 14:53:00-05:00  213.960  756.65  \n",
      "2021-01-06 14:54:00-05:00  214.230  759.90  \n",
      "2021-01-06 14:55:00-05:00  214.330  762.45  \n",
      "2021-01-06 14:56:00-05:00  214.380  763.04  \n",
      "2021-01-06 14:57:00-05:00  214.210  763.04  \n",
      "2021-01-06 14:58:00-05:00  214.180  762.30  \n",
      "2021-01-06 14:59:00-05:00  214.235  761.80  \n",
      "2021-01-06 15:00:00-05:00  214.070  761.24  \n"
     ]
    }
   ],
   "source": [
    "# Create the list of tickers\n",
    "\n",
    "ticker_list = ['FB','AMZN','AAPL','NFLX', 'GOOGL', 'MSFT', 'TSLA']\n",
    "# Define Dates\n",
    "\n",
    "beg_date = '2021-01-06'\n",
    "end_date = '2021-01-06'\n",
    "\n",
    "# Convert the date in a format the Alpaca API reqires\n",
    "start =  pd.Timestamp(f'{beg_date} 09:30:00-0400', tz='America/New_York').replace(hour=9, minute=30, second=0).astimezone('GMT').isoformat()[:-6]+'Z'\n",
    "end   =  pd.Timestamp(f'{end_date} 16:00:00-0400', tz='America/New_York').replace(hour=15, minute=0, second=0).astimezone('GMT').isoformat()[:-6]+'Z'\n",
    "timeframe='1Min'\n",
    "\n",
    "# Use iloc to get the last 10 mins every time we pull new data\n",
    "prices = alpaca.get_barset(ticker_list, \"minute\", start=start, end=end).df.iloc[-11:]\n",
    "prices.ffill(inplace=True)   \n",
    "\n",
    "# Create an empty DataFrame for closing prices\n",
    "df_closing_prices = pd.DataFrame()\n",
    "\n",
    "# Fetch the closing prices of our tickers\n",
    "df_closing_prices[\"FB\"] = prices[\"FB\"][\"close\"]\n",
    "df_closing_prices[\"AMZN\"] = prices[\"AMZN\"][\"close\"]\n",
    "df_closing_prices[\"AAPL\"] = prices[\"AAPL\"][\"close\"]\n",
    "df_closing_prices[\"NFLX\"] = prices[\"NFLX\"][\"close\"]\n",
    "df_closing_prices[\"GOOGL\"] = prices[\"GOOGL\"][\"close\"]\n",
    "df_closing_prices['MSFT'] = prices['MSFT'][\"close\"]\n",
    "df_closing_prices['TSLA'] = prices['TSLA'][\"close\"]\n",
    "\n",
    "print(df_closing_prices.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>1_m_returns</th>\n",
       "      <th>5_m_returns</th>\n",
       "      <th>10_m_returns</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>level_0</th>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FB</th>\n",
       "      <th>2021-01-06 15:00:00-05:00</th>\n",
       "      <td>-0.001960</td>\n",
       "      <td>-0.000151</td>\n",
       "      <td>0.000869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMZN</th>\n",
       "      <th>2021-01-06 15:00:00-05:00</th>\n",
       "      <td>-0.000717</td>\n",
       "      <td>-0.000555</td>\n",
       "      <td>0.000515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <th>2021-01-06 15:00:00-05:00</th>\n",
       "      <td>-0.002345</td>\n",
       "      <td>-0.002267</td>\n",
       "      <td>0.004091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NFLX</th>\n",
       "      <th>2021-01-06 15:00:00-05:00</th>\n",
       "      <td>0.000593</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>-0.000217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOGL</th>\n",
       "      <th>2021-01-06 15:00:00-05:00</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000070</td>\n",
       "      <td>-0.000778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSFT</th>\n",
       "      <th>2021-01-06 15:00:00-05:00</th>\n",
       "      <td>-0.000770</td>\n",
       "      <td>-0.001213</td>\n",
       "      <td>0.000654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSLA</th>\n",
       "      <th>2021-01-06 15:00:00-05:00</th>\n",
       "      <td>-0.000735</td>\n",
       "      <td>-0.001587</td>\n",
       "      <td>0.010500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   1_m_returns  5_m_returns  10_m_returns\n",
       "level_0 time                                                             \n",
       "FB      2021-01-06 15:00:00-05:00    -0.001960    -0.000151      0.000869\n",
       "AMZN    2021-01-06 15:00:00-05:00    -0.000717    -0.000555      0.000515\n",
       "AAPL    2021-01-06 15:00:00-05:00    -0.002345    -0.002267      0.004091\n",
       "NFLX    2021-01-06 15:00:00-05:00     0.000593     0.000257     -0.000217\n",
       "GOOGL   2021-01-06 15:00:00-05:00     0.000000    -0.000070     -0.000778\n",
       "MSFT    2021-01-06 15:00:00-05:00    -0.000770    -0.001213      0.000654\n",
       "TSLA    2021-01-06 15:00:00-05:00    -0.000735    -0.001587      0.010500"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create list of momentums\n",
    "list_of_momentums = [1,5,10]\n",
    "\n",
    "for i in list_of_momentums:  \n",
    "    # Compute percentage change for each one of the momentums in the momentum list\n",
    "    returns_temp = df_closing_prices.pct_change(i)\n",
    "    # Unstack the returns \n",
    "    returns_temp = pd.DataFrame(returns_temp.unstack())\n",
    "    name = f'{i}_m_returns'\n",
    "    returns_temp.rename(columns={0: name}, inplace = True)\n",
    "    # Reset the index so we can merge based on index\n",
    "    returns_temp.reset_index(inplace = True)\n",
    "    # Merge newly computed returns with previously created returns\n",
    "    if i ==1:\n",
    "        returns = returns_temp\n",
    "    else:\n",
    "        returns = pd.merge(returns,returns_temp,left_on=['level_0', 'time'],right_on=['level_0', 'time'], how='left', suffixes=('_original', 'right'))\n",
    "\n",
    "# Drop nulls and set index\n",
    "returns.dropna(axis=0, how='any', inplace=True)\n",
    "returns.set_index(['level_0', 'time'], inplace=True)\n",
    "\n",
    "# Generate feature data and preview first 10 rows.\n",
    "X = returns\n",
    "X.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Using `joblib`, load the chosen model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the previously trained and saved model using joblib\n",
    "\n",
    "final_model = joblib.load('log_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Use the model file to make predicttions:\n",
    "* Use `predict` on `X` and save this as `y_pred`.\n",
    "* Convert `y_pred` to a DataFrame, setting the index to the index of `X`.\n",
    "* Rename the column 0 to 'buy', be sure to set `inplace =True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model file to predict on X\n",
    "y_pred = final_model.predict(X)\n",
    "\n",
    "# Convert y_pred to a dataframe, set the index to the index of X\n",
    "y_pred_df = pd.DataFrame(y_pred, index=X.index)\n",
    "\n",
    "# Rename the column 0 to 'buy', be sure to set inplace =True\n",
    "y_pred_df.rename(columns={0:'buy'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>buy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>level_0</th>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FB</th>\n",
       "      <th>2021-01-06 15:00:00-05:00</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMZN</th>\n",
       "      <th>2021-01-06 15:00:00-05:00</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <th>2021-01-06 15:00:00-05:00</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NFLX</th>\n",
       "      <th>2021-01-06 15:00:00-05:00</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOGL</th>\n",
       "      <th>2021-01-06 15:00:00-05:00</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSFT</th>\n",
       "      <th>2021-01-06 15:00:00-05:00</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSLA</th>\n",
       "      <th>2021-01-06 15:00:00-05:00</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   buy\n",
       "level_0 time                          \n",
       "FB      2021-01-06 15:00:00-05:00    1\n",
       "AMZN    2021-01-06 15:00:00-05:00    1\n",
       "AAPL    2021-01-06 15:00:00-05:00    1\n",
       "NFLX    2021-01-06 15:00:00-05:00    0\n",
       "GOOGL   2021-01-06 15:00:00-05:00    1\n",
       "MSFT    2021-01-06 15:00:00-05:00    1\n",
       "TSLA    2021-01-06 15:00:00-05:00    0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Filter the stocks where 'buy' is equal to 1, saving the filter as `y_pred`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>buy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>level_0</th>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FB</th>\n",
       "      <th>2021-01-06 15:00:00-05:00</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMZN</th>\n",
       "      <th>2021-01-06 15:00:00-05:00</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <th>2021-01-06 15:00:00-05:00</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOGL</th>\n",
       "      <th>2021-01-06 15:00:00-05:00</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSFT</th>\n",
       "      <th>2021-01-06 15:00:00-05:00</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   buy\n",
       "level_0 time                          \n",
       "FB      2021-01-06 15:00:00-05:00    1\n",
       "AMZN    2021-01-06 15:00:00-05:00    1\n",
       "AAPL    2021-01-06 15:00:00-05:00    1\n",
       "GOOGL   2021-01-06 15:00:00-05:00    1\n",
       "MSFT    2021-01-06 15:00:00-05:00    1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the stocks where 'buy' is equal to 1\n",
    "\n",
    "buy_df = y_pred_df[y_pred_df['buy'] == 1]\n",
    "buy_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Using the `y_pred` filter, create a dictionary called `buy_dict` and assign 'n' to each Ticker (key value) as a placeholder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FB': 'n',\n",
       " 'AMZN': 'n',\n",
       " 'AAPL': 'n',\n",
       " 'NFLX': 'n',\n",
       " 'GOOGL': 'n',\n",
       " 'MSFT': 'n',\n",
       " 'TSLA': 'n'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dictionary from y_pred and assign a 'n' to each of them for now as a placeholder.\n",
    "buy_dict = dict.fromkeys(y_pred_df.index.get_level_values(0), 'n')\n",
    "buy_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Obtain the total available equity in your account from the Alpaca API and store in a variable called `total_capital`. You will split the capital equally between all selected stocks per the CIO's request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pull the total available equity in our account from the  Alpaca API\n",
    "\n",
    "total_capital = int(account.equity)\n",
    "total_capital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capital per stock: 14285.714285714286\n"
     ]
    }
   ],
   "source": [
    "# Compute capital per stock, divide equity in account by number of stocks\n",
    "# Use Alpaca API to pull the equity in the account\n",
    "if len(buy_dict) > 0:\n",
    "    capital_per_stock = float(total_capital)/ len(buy_dict)\n",
    "else:\n",
    "    capital_per_stock = 0\n",
    "print(f'Capital per stock: {capital_per_stock}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Use a for-loop to iterate through `buy_dict` to determine the number stocks you need to buy for each ticker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'FB': 54, 'AMZN': 4, 'AAPL': 112, 'NFLX': 28, 'GOOGL': 8, 'MSFT': 66, 'TSLA': 18}\n"
     ]
    }
   ],
   "source": [
    "# Use for loop to iterate through dictionary of buys \n",
    "# Determine the number stocks we need to buy for each ticker\n",
    "for ticker in buy_dict:\n",
    "    try:\n",
    "        buy_dict[ticker] = int(capital_per_stock /int(prices[ticker].iloc[-1]['close']))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(buy_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Cancel all previous orders in the Alpaca API (so you don't buy more than intended) and sell all currently held stocks to close all positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cancel all previous orders in the Alpaca API\n",
    "alpaca.cancel_all_orders()\n",
    "\n",
    "# Sell all currently held stocks to close all positions\n",
    "alpaca.close_all_positions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Iterate through `buy_dict` and send a buy order for each ticker with their corresponding number of shares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the longlist object and send a buy order for each ticker with a corresponding number of shares:\n",
    "\n",
    "for key,value in buy_dict.items():\n",
    "    alpaca.submit_order(symbol=key, qty=value, side=\"buy\", type=\"market\", time_in_force=\"day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpaca.cancel_all_orders()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automate the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Make a function called `trade()` that incorporates all of the steps above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add all of the steps conducted above into the function trade\n",
    "def trade():\n",
    "\n",
    "    ticker_list = ['FB','AMZN','AAPL','NFLX', 'GOOGL', 'MSFT', 'TSLA']\n",
    "    # Notice that we remove the start and end variables since we want the latest prices.\n",
    "    timeframe='1Min'\n",
    "    # Use iloc to get the last 10 mins every time we pull new data\n",
    "    prices = alpaca.get_barset(ticker_list, \"minute\").df.iloc[-11:]\n",
    "    prices.ffill(inplace=True)   \n",
    "\n",
    "    # Create and empty DataFrame for closing prices\n",
    "    df_closing_prices = pd.DataFrame()\n",
    "\n",
    "    # Fetch the closing prices of our tickers\n",
    "    df_closing_prices[\"FB\"] = prices[\"FB\"][\"close\"]\n",
    "    df_closing_prices[\"AMZN\"] = prices[\"AMZN\"][\"close\"]\n",
    "    df_closing_prices[\"AAPL\"] = prices[\"AAPL\"][\"close\"]\n",
    "    df_closing_prices[\"NFLX\"] = prices[\"NFLX\"][\"close\"]\n",
    "    df_closing_prices[\"GOOGL\"] = prices[\"GOOGL\"][\"close\"]\n",
    "    df_closing_prices['MSFT'] = prices['MSFT'][\"close\"]\n",
    "    df_closing_prices['TSLA'] = prices['TSLA'][\"close\"]\n",
    "    print(df_closing_prices.head())\n",
    "    \n",
    "    # Loop through momentums to build new DataFrame\n",
    "    list_of_momentums = [1,5,10]\n",
    "    for i in list_of_momentums:   \n",
    "        returns_temp = df_closing_prices.pct_change(i)\n",
    "        returns_temp = pd.DataFrame(returns_temp.unstack())\n",
    "        name = f'{i}_m_returns'\n",
    "        returns_temp.rename(columns={0: name}, inplace = True)\n",
    "        returns_temp.reset_index(inplace = True)\n",
    "        if i ==1:\n",
    "            returns = returns_temp\n",
    "        else:\n",
    "            returns = pd.merge(returns,returns_temp,left_on=['level_0', 'time'],right_on=['level_0', 'time'], how='left', suffixes=('_original', 'right'))\n",
    "\n",
    "    # Drop nulls and set index            \n",
    "    returns.dropna(axis=0, how='any', inplace=True)\n",
    "    returns.set_index(['level_0', 'time'], inplace=True)\n",
    "    \n",
    "    # Preprocess data for model\n",
    "    X = returns\n",
    "    final_model = joblib.load('log_model.pkl')\n",
    "    y_pred = final_model.predict(X)\n",
    "    y_pred_df = pd.DataFrame(y_pred, index=X.index)\n",
    "    y_pred_df.rename(columns={0:'buy'}, inplace=True)\n",
    "    buy_df = y_pred_df[y_pred_df['buy'] == 1]\n",
    "\n",
    "    # Create the `buy_dict` object\n",
    "    buy_dict = dict.fromkeys(y_pred_df.index.get_level_values(0), 'n')\n",
    "    \n",
    "    # Split capital between stocks and determine buy or sell\n",
    "    total_capital = int(account.equity)\n",
    "    if len(buy_dict) > 0:\n",
    "        capital_per_stock = float(total_capital)/ len(buy_dict)\n",
    "    else:\n",
    "        capital_per_stock = 0\n",
    "    for ticker in buy_dict:\n",
    "        try:\n",
    "            buy_dict[ticker] = int(capital_per_stock /int(prices[ticker].iloc[-1]['close']))\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # Cancel pending orders and close positions\n",
    "    alpaca.cancel_all_orders()\n",
    "    alpaca.close_all_positions()\n",
    "   \n",
    "    \n",
    "    # Submit orders\n",
    "    for key,value in buy_dict.items():\n",
    "        alpaca.submit_order(symbol=key, qty=value, side=\"buy\", type=\"market\", time_in_force=\"day\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Import Python's schedule module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'schedule'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-f58e0d703bc4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Import Python's schedule module\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mschedule\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'schedule'"
     ]
    }
   ],
   "source": [
    "# Import Python's schedule module \n",
    "import schedule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Use the \"schedule\" module to automate the algorithm:\n",
    "* Clear the schedule with `.clear()`.\n",
    "* Define a schedule to run the trade function every minute at 5 seconds past the minute mark (e.g. `10:31:05`).\n",
    "* Use the Alpaca API to check whether the market is open.\n",
    "* Use run_pending() function inside schedule to execute the schedule you defined while the market is open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear the schedule\n",
    "schedule.clear()\n",
    "\n",
    "# Define a schedule to run the trade function every minute at 5 seconds past the minute mark (e.g. 10:31:05)\n",
    "schedule.every().minute.at(\":05\").do(trade)\n",
    "\n",
    "# Use the Alpaca API to check whether the market is open\n",
    "clock = alpaca.get_clock()\n",
    "\n",
    "# Use run_pending() function inside schedule to execute the schedule you defined as long as the market is open\n",
    "while clock.is_open:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyvizenv] *",
   "language": "python",
   "name": "conda-env-pyvizenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
